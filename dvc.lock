schema: '2.0'
stages:
  data_prep:
    cmd: python src/utils/prepare_slamllm_data.py --config params.yaml
    deps:
    - path: data/speech_massive_data/hf_parquet_data
      hash: md5
      md5: 43105b9b33dfdc3dca3057b29a71b9a9.dir
      size: 5243193877
      nfiles: 3
    - path: src/utils/prepare_slamllm_data.py
      hash: md5
      md5: 3825bf036fc9cdc2e4171253cff410a6
      size: 3558
    params:
      params.yaml:
        prepare:
          base_dir: /stek/corpora/Speech-MASSIVE/
          json_slam_files: data/speech_massive_data/slamllm_json_data
          lang: fr-FR
          train_split: train
          task: asr_ic_sf
    outs:
    - path: data/speech_massive_data/slamllm_json_data
      hash: md5
      md5: 0f0e8006c36991378acd7e04b17a1896.dir
      size: 4853460
      nfiles: 3
  finetune:
    cmd: bash SLAM-LLM/examples/asr_librispeech/scripts/finetune.sh /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
      /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5 
      /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train_asr_ic_sf.jsonl
      /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev_asr_ic_sf.jsonl
      0.0001 vicuna-7b-v1.5 4096 wavlm 5 1024 linear 3 1000 100000 2 2 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
    deps:
    - path: SLAM-LLM/examples/asr_librispeech/scripts/finetune.sh
      hash: md5
      md5: 8e239bd599a01c3e8fa604014d29cb17
      size: 3128
    - path: data/speech_massive_data/slamllm_json_data
      hash: md5
      md5: 0f0e8006c36991378acd7e04b17a1896.dir
      size: 4853460
      nfiles: 3
    params:
      params.yaml:
        train:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          train_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train_asr_ic_sf.jsonl
          val_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev_asr_ic_sf.jsonl
          learn_rate: 0.0001
          llm_name: vicuna-7b-v1.5
          llm_dim: 4096
          encoder_name: wavlm
          encoder_projector_ds_rate: 5
          encoder_dim: 1024
          encoder_projector: linear
          num_epochs: 3
          warmup_steps: 1000
          total_steps: 100000
          batch_size_training: 2
          val_batch_size: 2
    outs:
    - path: train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
      hash: md5
      md5: a3c5af1b55d6632bcb97dc6c84c460a9.dir
      size: 1587374834
      nfiles: 26
  decode:
    cmd: bash SLAM-LLM/examples/asr_librispeech/scripts/decode.sh /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
      /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
      speech_massive_fr-FR_test_asr_ic_sf /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data
      vicuna-7b-v1.5 4096 wavlm 1024 linear 3 2
    deps:
    - path: SLAM-LLM/examples/asr_librispeech/scripts/decode.sh
      hash: md5
      md5: 9c84b9bb0ece0059479744778ad2a941
      size: 2549
    - path: train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
      hash: md5
      md5: 7a6e20941efb7fd1ba47f5ad801080b4.dir
      size: 1588367852
      nfiles: 33
    params:
      params.yaml:
        decode:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          split: speech_massive_fr-FR_test_asr_ic_sf
          test_data_path: /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data
          val_batch_size: 2
        train:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          train_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train_asr_ic_sf.jsonl
          val_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev_asr_ic_sf.jsonl
          learn_rate: 0.0001
          llm_name: vicuna-7b-v1.5
          llm_dim: 4096
          encoder_name: wavlm
          encoder_projector_ds_rate: 5
          encoder_dim: 1024
          encoder_projector: linear
          num_epochs: 3
          warmup_steps: 1000
          total_steps: 100000
          batch_size_training: 2
          val_batch_size: 2
  evaluate:
    cmd: python src/utils/evaluate_exp.py --config params.yaml
    params:
      params.yaml:
        evaluate:
          ground_truth_file: 
            /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm/asr_epoch_4_step_3729/decode_speech_massive_fr-FR_test_asr_ic_sf_beam4_gt
          prediction_file: 
            /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm/asr_epoch_4_step_3729/decode_speech_massive_fr-FR_test_asr_ic_sf_beam4_pred
          evaluate_log: 
            /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm/asr_epoch_4_step_3729/evaluate.log
