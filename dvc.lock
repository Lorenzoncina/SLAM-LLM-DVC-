schema: '2.0'
stages:
  data_prep:
    cmd: python src/utils/prepare_slamllm_data.py --config params.yaml
    deps:
    - path: data/speech_massive_data/hf_parquet_data
      hash: md5
      md5: 43105b9b33dfdc3dca3057b29a71b9a9.dir
      size: 5243193877
      nfiles: 3
    - path: src/utils/prepare_slamllm_data.py
      hash: md5
      md5: cb2331c3ecdb2413f8d870ca72302c1c
      size: 3234
    params:
      params.yaml:
        prepare:
          base_dir: /stek/corpora/Speech-MASSIVE/
          json_slam_files: data/speech_massive_data/slamllm_json_data
          lang: fr-FR
          train_split: train
    outs:
    - path: data/speech_massive_data/slamllm_json_data
      hash: md5
      md5: e19d5c66c182f3fc66f988eb1dc0fe62.dir
      size: 3527523
      nfiles: 3
  finetune:
    cmd: bash SLAM-LLM/examples/asr_librispeech/scripts/finetune.sh /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
      /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5 
      /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train.jsonl
      /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev.jsonl
      0.0001 vicuna-7b-v1.5 4096 wavlm 5 1024 linear 3 1000 100000 2 2 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
    deps:
    - path: SLAM-LLM/examples/asr_librispeech/scripts/finetune.sh
      hash: md5
      md5: 8e239bd599a01c3e8fa604014d29cb17
      size: 3128
    - path: data/speech_massive_data/slamllm_json_data
      hash: md5
      md5: e19d5c66c182f3fc66f988eb1dc0fe62.dir
      size: 3527523
      nfiles: 3
    params:
      params.yaml:
        train:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          train_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train.jsonl
          val_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev.jsonl
          learn_rate: 0.0001
          llm_name: vicuna-7b-v1.5
          llm_dim: 4096
          encoder_name: wavlm
          encoder_projector_ds_rate: 5
          encoder_dim: 1024
          encoder_projector: linear
          num_epochs: 3
          warmup_steps: 1000
          total_steps: 100000
          batch_size_training: 2
          val_batch_size: 2
    outs:
    - path: train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
      hash: md5
      md5: 28ec8f3f330e8197f2544d559e7dcd59.dir
      size: 1587372394
      nfiles: 26
  decode:
    cmd: bash SLAM-LLM/examples/asr_librispeech/scripts/decode.sh /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
      /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
      speech_massive_fr-FR_test /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data
      vicuna-7b-v1.5 4096 wavlm 1024 linear 3 2
    deps:
    - path: SLAM-LLM/examples/asr_librispeech/scripts/decode.sh
      hash: md5
      md5: 037d7f7fa2d26ba6587a1dd6906159aa
      size: 2549
    - path: train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep0.0001-wavlm
      hash: md5
      md5: 7e5971ccb578883347f26b059c0b4292.dir
      size: 1587911117
      nfiles: 33
    params:
      params.yaml:
        decode:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          split: speech_massive_fr-FR_test
          test_data_path: /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data
          val_batch_size: 2
        train:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          train_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train.jsonl
          val_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev.jsonl
          learn_rate: 0.0001
          llm_name: vicuna-7b-v1.5
          llm_dim: 4096
          encoder_name: wavlm
          encoder_projector_ds_rate: 5
          encoder_dim: 1024
          encoder_projector: linear
          num_epochs: 3
          warmup_steps: 1000
          total_steps: 100000
          batch_size_training: 2
          val_batch_size: 2
