schema: '2.0'
stages:
  data_prep:
    cmd: python src/utils/prepare_slamllm_data.py --config params.yaml
    deps:
    - path: data/speech_massive_data/hf_parquet_data
      hash: md5
      md5: 43105b9b33dfdc3dca3057b29a71b9a9.dir
      size: 5243193877
      nfiles: 3
    - path: src/utils/prepare_slamllm_data.py
      hash: md5
      md5: 3825bf036fc9cdc2e4171253cff410a6
      size: 3558
    params:
      params.yaml:
        prepare:
          base_dir: /stek/corpora/Speech-MASSIVE/
          json_slam_files: data/speech_massive_data/slamllm_json_data
          lang: fr-FR
          train_split: train
          task: asr_ic_sf
    outs:
    - path: data/speech_massive_data/slamllm_json_data
      hash: md5
      md5: 0f0e8006c36991378acd7e04b17a1896.dir
      size: 4853460
      nfiles: 3
  finetune:
    cmd: bash SLAM-LLM/examples/asr_librispeech/scripts/finetune.sh /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
      /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5 
      /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train_asr_ic_sf.jsonl
      /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev_asr_ic_sf.jsonl
      0.0001 vicuna-7b-v1.5 4096 wavlm 5 1024 linear 3 1000 100000 2 2 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
    deps:
    - path: SLAM-LLM/examples/asr_librispeech/scripts/finetune.sh
      hash: md5
      md5: 1b8433ef100ebe53400090929d879ee2
      size: 3128
    - path: data/speech_massive_data/slamllm_json_data
      hash: md5
      md5: 0f0e8006c36991378acd7e04b17a1896.dir
      size: 4853460
      nfiles: 3
    params:
      params.yaml:
        train:
          experiment_date: '20240320'
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          train_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train_asr_ic_sf.jsonl
          val_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev_asr_ic_sf.jsonl
          output_dir: 
            /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
          learn_rate: 0.0001
          llm_name: vicuna-7b-v1.5
          llm_dim: 4096
          encoder_name: wavlm
          encoder_projector_ds_rate: 5
          encoder_dim: 1024
          encoder_projector: linear
          num_epochs: 3
          warmup_steps: 1000
          total_steps: 100000
          batch_size_training: 2
          val_batch_size: 2
    outs:
    - path: 
        train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
      hash: md5
      md5: 4ba53e05067f5baa96694d10e064abc2.dir
      size: 1283961749
      nfiles: 22
  decode:
    cmd: bash SLAM-LLM/examples/asr_librispeech/scripts/decode.sh /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
      /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
      speech_massive_fr-FR_test_asr_ic_sf /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data
      vicuna-7b-v1.5 4096 wavlm 1024 linear 3 2 asr_epoch_3_step_5486/
    deps:
    - path: SLAM-LLM/examples/asr_librispeech/scripts/decode.sh
      hash: md5
      md5: df2ed4e316b8c7ece8ef30d0627814b2
      size: 2579
    - path: 
        train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
      hash: md5
      md5: 148b3a7d86cd373ae3b7220cb9dfa904.dir
      size: 1284953771
      nfiles: 29
    params:
      params.yaml:
        decode:
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          split: speech_massive_fr-FR_test_asr_ic_sf
          test_data_path: /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data
          val_batch_size: 2
          ckpt_path: asr_epoch_3_step_5486/
        train:
          experiment_date: '20240320'
          speech_encoder_path: /stek/lconcina/SLAM-LLM-DVC-/models/WavLM-Large.pt
          llm_path: /stek/lconcina/SLAM-LLM-DVC-/models/vicuna-7b-v1.5
          train_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_train_asr_ic_sf.jsonl
          val_data_path: 
            /stek/lconcina/SLAM-LLM-DVC-/data/speech_massive_data/slamllm_json_data/speech_massive_fr-FR_dev_asr_ic_sf.jsonl
          output_dir: 
            /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
          learn_rate: 0.0001
          llm_name: vicuna-7b-v1.5
          llm_dim: 4096
          encoder_name: wavlm
          encoder_projector_ds_rate: 5
          encoder_dim: 1024
          encoder_projector: linear
          num_epochs: 3
          warmup_steps: 1000
          total_steps: 100000
          batch_size_training: 2
          val_batch_size: 2
  evaluate:
    cmd: python src/utils/evaluate_exp.py --config params.yaml --output_dir 
      /stek/lconcina/SLAM-LLM-DVC-/train_output/vicuna-7b-v1.5-speechMassive-linear-steplrwarmupkeep1e-4-wavlm-20250320
    params:
      params.yaml:
        evaluate:
          ground_truth_file: decode_speech_massive_fr-FR_test_asr_ic_sf_beam4_gt
          prediction_file: decode_speech_massive_fr-FR_test_asr_ic_sf_beam4_pred
          evaluate_log: evaluate_2.log
